{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2sql_2_BERT.ipynb","provenance":[],"mount_file_id":"1BgC6Q3Qh6Ks-0U-MC2eOHues-yVGGyWj","authorship_tag":"ABX9TyPbhxvM5VeV88wD9DXTUq3T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ei5ctO3gvVXJ","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Project_3/seq2sql\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAp5fBlSwAAO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"3a180ddf-70d1-44a7-adf9-25aed87a0439","executionInfo":{"status":"ok","timestamp":1584496665520,"user_tz":300,"elapsed":1320,"user":{"displayName":"Jiuqi Xian","photoUrl":"","userId":"06178009721688935485"}}},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["data\t\t\t       model.py      temp.py   wiki_sql.py\n","data-20200306T075156Z-001.zip  __pycache__   train.py\n","extract_data.py\t\t       saved_models  utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ktFXM0g1XF4X","colab_type":"code","colab":{}},"source":["!pip install pytorch-pretrained-bert"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RRexgMVFXI1G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1b1f99d8-f201-4e09-f096-3b5390377a3b","executionInfo":{"status":"ok","timestamp":1584497245063,"user_tz":300,"elapsed":1680,"user":{"displayName":"Jiuqi Xian","photoUrl":"","userId":"06178009721688935485"}}},"source":["import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","#logging.basicConfig(level=logging.INFO)\n","\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 1170324.75B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZHCNsQbBZTS3","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from utils import get_next_decoder\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","class Encoder(nn.Module):\n","\n","    def __init__(self, emb_dim, hidden_size, decoder_hidden_size, vocab_size):\n","        \"\"\"\n","        Args:\n","            emb_dim (int): Embedding size\n","            hidden_size (int): Encoder hidden size\n","            decoder_hidden_size (int): Decoder hidden size\n","            vocab_size (int): Size of vocab\n","        \"\"\"\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.gru = nn.GRU(emb_dim, hidden_size, bidirectional=True, dropout=0.2)\n","\n","        self.fc = nn.Linear(hidden_size * 2, decoder_hidden_size)\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x(tensor): Input sentence of size (src len, batch size)\n","        Returns: Encoder output (src len, batch size, hidden * 2) and hidden (batch size, decoder_hidden_size)\n","        \"\"\"\n","        # print(\"x device1\", x.device)\n","        # x = x.long().cuda()\n","        # print(\"x device2\", x.device)\n","        x = self.dropout(self.embedding(x.long().cpu()))                                                                      # (src len, batch size, emb_dim)\n","        x, h = self.gru(x)\n","        h = torch.cat((h[-2, :, :], h[-1, :, :]), dim=1)                                                                # concat last forward and backward cell's outputs\n","        h = torch.tanh(self.fc(h))\n","        return x, h\n","\n","\n","class Decoder(nn.Module):\n","\n","    def __init__(self, emb_dim, vocab_size, hidden_size, encoder_hidden_size, decoder_vocab_dict, global_dict):\n","        \"\"\"\n","        Args:\n","            emb_dim (int): Embedding size\n","            vocab_size (int): Size of vocab\n","            hidden_size (int): Decoder hidden size\n","            encoder_hidden_size (int): Encoder hidden size\n","            decoder_vocab_dict (dict): Dictionary of decoder vocab\n","            global_dict (dict): Dictionary of full vocab\n","        \"\"\"\n","        super(Decoder, self).__init__()\n","        output_dim = len(decoder_vocab_dict.keys())\n","        self.hidden_size = hidden_size\n","        self.decoder_vocab_dict = decoder_vocab_dict\n","        self.global_dict = global_dict\n","\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.gru = nn.GRU((encoder_hidden_size * 2) + emb_dim, hidden_size, dropout=0.2)\n","\n","        self.attn_fc = nn.Linear((encoder_hidden_size * 2) + hidden_size, 1)\n","\n","        self.fc = nn.Linear((encoder_hidden_size * 2) + hidden_size + emb_dim, output_dim)\n","        self.dropout = nn.Dropout(0.2)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, sql, idx, h, encoder_outputs, decoder_dict, current_decoder, predictions=None, targets=None,\n","                decoders=None, print_output=False):\n","        \"\"\"\n","        Args:\n","            sql (tensor): Tensor of all sql (batch_size, src len)\n","            idx (int): Index of current input\n","            h (tensor): (batch_size, hidden_size)\n","            encoder_outputs (tensor): (src len, batch size, enc_hid_dim * 2)\n","            decoder_dict (dict): Dictionary of decoder models\n","            current_decoder (str): Current decoder name\n","            predictions (list): List of all predictions\n","            targets (list): List of targets in local dictionary mappings\n","            decoders (list): List of decoders for each prediction\n","            print_output (bool): If true, give output on screen\n","        Returns: Decoder output (batch size, vocab) and hidden (1, batch size, hidden)\n","        \"\"\"\n","        if decoders is None:\n","            decoders, targets, predictions = [], [], []\n","        if print_output:\n","            print('\\n\\nCurrent Decoder: {}\\ni = {}'.format(current_decoder, idx))\n","        if current_decoder == 'RootDecoder':\n","            next_decoders = get_next_decoder(current_decoder, decoder_dict)\n","\n","            for next_decoder, decoder_name in next_decoders:\n","                idx += 1\n","                if decoder_name == 'AggregatorDecoder':\n","                    # predictions.append(torch.tensor([26173]))                                                         # select\n","                    # targets.append(torch.tensor([26173]))\n","                    idx += 1\n","                elif decoder_name == 'TableDecoder':\n","                    # predictions.append(torch.tensor([19884]))                                                         # from\n","                    # targets.append(torch.tensor([19884]))\n","                    idx += 1\n","                predictions, targets, decoders, idx = next_decoder(sql, idx, h, encoder_outputs, decoder_dict,\n","                                                                   decoder_name, predictions, targets, decoders,\n","                                                                   print_output)\n","\n","                if idx == sql.size(1):\n","                    return predictions, targets, decoders\n","\n","            if idx != sql.size(1):\n","                predictions.extend([predictions[-1] for x in range(sql.size(1) - idx)])                                 # appending padding of 1s to punish decoder for not predicting the remaining words\n","                targets.extend([targets[-1] for x in range(sql.size(1) - idx)])                                         # appending padding of 0s\n","                decoders.extend([decoders[-1] for x in range(sql.size(1) - idx)])\n","\n","            return predictions, targets, decoders\n","\n","        if idx == sql.size(1):\n","            return predictions, targets, decoders, idx\n","        x = sql[:, idx]\n","\n","        # Attention\n","        src_len = encoder_outputs.shape[0]\n","        h_rep = h.unsqueeze(1).repeat(1, src_len, 1)                                                                    # (batch size, src len, dec hid dim) 5, 100, 20\n","        encoder_outputs_rearranged = encoder_outputs.permute(1, 0, 2)                                                   # (batch size, src len, enc_hid_dim * 2) 5, 100, 100\n","        weights = torch.tanh(self.attn_fc(torch.cat((h_rep, encoder_outputs_rearranged), dim=2)))                       # (batch size, src len, 1)\n","\n","        embedded = self.embedding(x.long()).squeeze(1)                                                                  # (batch_size, emb_dim)\n","        embedded = self.dropout(embedded)\n","\n","        weighted = torch.bmm(encoder_outputs_rearranged.permute(0, 2, 1), weights).squeeze(2)                           # (batch size, enc_hid_dim * 2)\n","        x = torch.cat((embedded, weighted), dim=1)                                                                      # (batch size, emb_dim + enc_hid_dim*2)\n","        x, h = self.gru(x.unsqueeze(0), h.unsqueeze(0))                                                                 # src size = 1\n","\n","        # assert (x == h).all()\n","\n","        x = self.softmax(self.fc(torch.cat((x.squeeze(0), weighted, embedded), dim=1)))                                 # (batch size, output_dim)\n","        # x = x.argmax(1)                                                                                               # (batch_size, 1)\n","        # for n, index in enumerate(x):                                                                                   # Decoder vocab to word mapping\n","        #     print(self.decoder_vocab_dict[index.item()])\n","        #     x[n] = self.global_dict[self.decoder_vocab_dict[index.item()]]\n","        if x.argmax(1) != x.size(1) - 1 or current_decoder not in ['KeywordDecoder', 'OperatorDecoder', 'AndOrDecoder',\n","                                                                   'AggregatorDecoder']:\n","            if print_output:\n","                print('Predicted: {}\\nTarget: {}'.format(list(self.decoder_vocab_dict.keys())[x.argmax(1).item()],\n","                                                               self.global_dict[int(sql[:, idx].item())]))\n","            predictions.append(x)\n","            try:\n","                targets.append(torch.tensor([self.decoder_vocab_dict[self.global_dict[sql[:, idx].item()]]]))\n","            except KeyError:\n","                targets.append(torch.tensor([x.size(1) - 1]))\n","            decoders.append(current_decoder)\n","\n","            next_decoders = get_next_decoder(current_decoder, decoder_dict)\n","\n","            if self.global_dict[int(sql[:, idx].item())] not in self.decoder_vocab_dict.keys():                         # Wrong decoder\n","                idx -= 1\n","                return predictions, targets, decoders, idx\n","            for next_decoder, decoder_name in next_decoders:\n","                idx = idx + 1\n","                predictions, targets, decoders, idx = next_decoder(sql, idx, h.squeeze(0), encoder_outputs,\n","                                                                   decoder_dict, decoder_name, predictions,\n","                                                                   targets, decoders, print_output)\n","        else:                                                                                                           # None\n","            if self.global_dict[int(sql[:, idx].item())] in self.decoder_vocab_dict.keys():                             # Wrongly predicted None\n","                predictions.append(x)\n","                try:\n","                    targets.append(torch.tensor([self.decoder_vocab_dict[self.global_dict[sql[:, idx].item()]]]))\n","                except KeyError:\n","                    targets.append(torch.tensor([x.size(1) - 2]))\n","                decoders.append(current_decoder)\n","            else:\n","                idx -= 1\n","\n","        return predictions, targets, decoders, idx\n","\n","\n","# if __name__ == \"__main__\":\n","#     encoder = Encoder(3, 50, 40, 1000)\n","#     inp = torch.randint(0, 1000, (100, 5))\n","#     output = encoder(inp)\n","#     print(output[0].size(), output[1].size())\n","#\n","#     decoder = Decoder(3, 1000, 40, 50)\n","#     print(decoder(torch.randint(0, 1000, (5, 1)), output[1], output[0]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"okMMI1tJdKHO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"82d23e22-3de9-4d71-c0b2-56b05e049ff8","executionInfo":{"status":"ok","timestamp":1584500097979,"user_tz":300,"elapsed":16712,"user":{"displayName":"Jiuqi Xian","photoUrl":"","userId":"06178009721688935485"}}},"source":["import torch\n","from torch import optim\n","import torch.nn as nn\n","from wiki_sql import WikiSQL\n","# from model import Encoder, Decoder\n","from torch.utils.data import DataLoader\n","from extract_data import load_pickle\n","import os\n","from tqdm import tqdm\n","from utils import get_decoder_vocab_dicts, save_models, zero_all_grads\n","from extract_data import load_pickle\n","import os\n","import matplotlib.pyplot as plt\n","\n","root = 'data'\n","# questions_path = 'data/questions/'\n","# sql_queries_path = 'data/sql_queries/'\n","# word_idx_mappings_path = 'data/word_idx_mappings/'\n","# wiki_sql_path = 'data/WikiSQL_files/'\n","vocab_size = 1                                                                                                          # Size of vocab, set later\n","enc_hidden_size = 40                                                                                                    # Size of h from each LSTM cell encoder        2*enc > dec\n","dec_hidden_size = 30                                                                                                    # Should be even\n","num_layers = 1                                                                                                          # Number of LSTM cells stacked one above other. Not used\n","num_epochs = 10\n","learning_rate = 3e-5\n","sequence_length = 1                                                                                                     # One word per lstm cell (not used)\n","encoder_output_size = 0                                                                                                 # Size of encoding and size of decoder input\n","batch_size = 1\n","embed_dim = 50\n","# keyword_output_dim = 2                                                                                                  # [where, none]\n","# column_output_dim = 0                                                                                                   # no of col in vocab, set later\n","# table_output_dim = 0                                                                                                    # no of tables in vocab, set later\n","# operator_output_dim = 6                                                                                                 # {>, <, =, <=, >=, !=, none}\n","# aggregator_output_dim = 6                                                                                               # {max, min, count, sum, avg, none}\n","# # root_output_dim = 0                                                                                                   # no of tables in vocab, set later\n","# and_or_output_dim = 3                                                                                                   # {and, or, none}\n","# constant_output_dim = 0                                                                                                 # V + col. Set later\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","if __name__ == \"__main__\":\n","\n","    train_transformed_dataset = WikiSQL(text=os.path.join(root, 'train/train_questions_tokenized.pkl'),\n","                                        sql=os.path.join(root, 'train/train_sql_tokenized.pkl'),\n","                                        schema=os.path.join(root, 'train/', 'train_schema.pkl')\n","                                        )\n","\n","    test_transformed_dataset = WikiSQL(text=os.path.join(root, 'test/test_questions_tokenized.pkl'),\n","                                        sql=os.path.join(root, 'test/test_sql_tokenized.pkl'),\n","                                       schema=os.path.join(root, 'test/test_schema.pkl')\n","                                       )\n","\n","    valid_transformed_dataset = WikiSQL(text=os.path.join(root, 'valid/valid_questions_tokenized.pkl'),\n","                                        sql=os.path.join(root, 'valid/valid_sql_tokenized.pkl'),\n","                                        schema=os.path.join(root, 'valid/valid_schema.pkl')\n","                                        )\n","\n","    word2idx = load_pickle(os.path.join(root, 'word_idx_mappings/word2idx.pkl'))\n","    idx2word = load_pickle(os.path.join(root, 'word_idx_mappings/idx2word.pkl'))\n","    col_dict = load_pickle(os.path.join(root, 'word_idx_mappings/column_mappings1.pkl'))\n","    table_dict = load_pickle(os.path.join(root, 'word_idx_mappings/table_mappings1.pkl'))\n","    vocab_size = len(word2idx.keys())\n","\n","    vocab_dicts = get_decoder_vocab_dicts(word2idx, table_dict, col_dict)\n","\n","    train_loader = DataLoader(train_transformed_dataset, batch_size=batch_size, shuffle=False,\n","                              collate_fn=train_transformed_dataset.collate)\n","    test_loader = DataLoader(test_transformed_dataset, batch_size=batch_size, shuffle=True,\n","                             collate_fn=test_transformed_dataset.collate)\n","    valid_loader = DataLoader(valid_transformed_dataset, batch_size=batch_size, shuffle=True,\n","                              collate_fn=valid_transformed_dataset.collate)\n","    loss = nn.NLLLoss()\n","\n","    # emb_dim, hidden_size, decoder_hidden_size, vocab_size\n","    encoder_dict = {\n","        'QuestionEncoder': Encoder(embed_dim, enc_hidden_size, int(dec_hidden_size / 2), vocab_size),\n","        'SchemaEncoder': Encoder(embed_dim, enc_hidden_size, int(dec_hidden_size / 2), vocab_size)\n","    }\n","\n","    # emb_dim, vocab_size, hidden_size, encoder_hidden_size, output_dim, decoder_vocab_dict, global_dict\n","    decoder_dict = {\n","        'KeywordDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['KeywordDecoder'], idx2word).to(device),\n","        'ColumnDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['ColumnDecoder'], idx2word).to(device),\n","        'TableDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['TableDecoder'], idx2word).to(device),\n","        'OperatorDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['OperatorDecoder'], idx2word).to(device),\n","        'AggregatorDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['AggregatorDecoder'], idx2word).to(device),\n","        'RootDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['RootDecoder'], idx2word).to(device),\n","        'AndOrDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['AndOrDecoder'], idx2word).to(device),\n","        'ConstantDecoder': Decoder(embed_dim, vocab_size, dec_hidden_size, enc_hidden_size, vocab_dicts['ConstantDecoder'], idx2word).to(device)\n","    }\n","\n","    encoder_optimizer, decoder_optimizer = {}, {}\n","    for name, encoder in encoder_dict.items():\n","        encoder_optimizer[name] = optim.Adam(encoder.parameters(), lr=learning_rate)\n","    for name, decoder in decoder_dict.items():\n","        decoder_optimizer[name] = optim.Adam(decoder.parameters(), lr=learning_rate)\n","\n","    total_step = len(train_loader)\n","    losses = []\n","    for epoch in range(num_epochs):\n","        total_cost = 0\n","        for n, sample in enumerate(tqdm(train_loader)):\n","\n","            text = sample[0].to(device)\n","            sql = sample[1].to(device)\n","            schema = sample[2].to(device)\n","\n","            question_enc_outputs, question_enc_hidden = encoder_dict['QuestionEncoder'](text.t())\n","            question_enc_outputs = question_enc_outputs.to(device)\n","            question_enc_hidden = question_enc_hidden.to(device)\n","            schema_enc_outputs, schema_enc_hidden = encoder_dict['SchemaEncoder'](schema.t())\n","            schema_enc_outputs = schema_enc_outputs.to(device)\n","            schema_enc_hidden = schema_enc_hidden.to(device)\n","\n","            hidden = torch.cat((question_enc_hidden, schema_enc_hidden), dim=-1)\n","            enc_outputs = torch.cat((question_enc_outputs, schema_enc_outputs), dim=0)\n","\n","            if n in [0, int(len(train_loader) / 3), 2 * int(len(train_loader) / 3)]:\n","                print_outputs = True\n","                print('\\n\\nText: {}\\nSQL: {}'.format(' '.join(list(map(lambda i: idx2word[i.item()], text[0]))),\n","                                                     ' '.join(list(map(lambda i: idx2word[i.item()], sql[0])))))\n","            else:\n","                print_outputs = False\n","\n","            # sql, idx, h, encoder_outputs, decoder_dict, current_decoder, predictions, print_outputs\n","            outputs, targets, decoders = decoder_dict['RootDecoder'](sql, 0, hidden, enc_outputs, decoder_dict, 'RootDecoder', print_output=print_outputs)\n","            # print(sql, targets, outputs)\n","            # where_pos = list(map(len, outputs))\n","\n","            # cost = loss(outputs[0], targets[0])\n","            epoch_loss = 0\n","            for output, target, decoder_name in zip(outputs, targets, decoders):\n","                target = target.cuda()\n","                zero_all_grads(encoder_optimizer, decoder_optimizer)\n","                cost = loss(output, target)\n","                cost.backward(retain_graph=True)\n","                decoder_optimizer[decoder_name].step()\n","                epoch_loss += cost\n","\n","            zero_all_grads(encoder_optimizer, decoder_optimizer)                                                        # Zeros grads for all encoders\n","            epoch_loss.backward()                                                                                       # Backward for encoder loss\n","            for encoder in encoder_optimizer.values():\n","                encoder.step()\n","\n","            total_cost += epoch_loss.double()\n","\n","            # if n == 3:\n","            #     break\n","\n","        valid_loss = 0\n","        with torch.no_grad():\n","            for n, sample in enumerate(tqdm(valid_loader)):\n","\n","                text = sample[0].to(device)\n","                sql = sample[1].to(device)\n","                schema = sample[2].to(device)\n","\n","                question_enc_outputs, question_enc_hidden = encoder_dict['QuestionEncoder'](text.t())\n","                question_enc_outputs = question_enc_outputs.to(device)\n","                question_enc_hidden = question_enc_hidden.to(device)\n","                schema_enc_outputs, schema_enc_hidden = encoder_dict['SchemaEncoder'](schema.t())\n","                schema_enc_outputs = schema_enc_outputs.to(device)\n","                schema_enc_hidden = schema_enc_hidden.to(device)\n","\n","                hidden = torch.cat((question_enc_hidden, schema_enc_hidden), dim=-1)\n","                enc_outputs = torch.cat((question_enc_outputs, schema_enc_outputs), dim=0)\n","\n","                if n in [0, int(len(train_loader) / 3), 2 * int(len(train_loader) / 3)]:\n","                    print_outputs = True\n","                    print('\\n\\nText: {}\\nSQL: {}'.format(' '.join(list(map(lambda i: idx2word[i.item()], text[0]))),\n","                                                         ' '.join(list(map(lambda i: idx2word[i.item()], sql[0])))))\n","                else:\n","                    print_outputs = False\n","\n","                # sql, idx, h, encoder_outputs, decoder_dict, current_decoder, predictions, print_outputs\n","                outputs, targets, decoders = decoder_dict['RootDecoder'](sql, 0, hidden, enc_outputs, decoder_dict, 'RootDecoder', print_output=print_outputs)\n","\n","                # print(sql, targets, outputs)\n","                # where_pos = list(map(len, outputs))\n","\n","                # cost = loss(outputs[0], targets[0])\n","                epoch_loss = 0\n","                for output, target, decoder_name in zip(outputs, targets, decoders):\n","                    target = target.cuda()\n","                    zero_all_grads(encoder_optimizer, decoder_optimizer)\n","                    epoch_loss += loss(output, target)\n","\n","                valid_loss += epoch_loss.double()\n","\n","                if n == 3:\n","                    break\n","\n","            print('Epoch: {}    total_cost =  {}    validLoss = {}'.format(epoch, total_cost, valid_loss))\n","        save_models(encoder_dict, decoder_dict, epoch)\n","\n","        losses.append([total_cost, valid_loss])\n","\n","        if epoch == 4:\n","            break\n","\n","    plt.plot(losses)\n","    plt.show()\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/56355 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> tell me what the notes are for south australia </s>\n","SQL: <s> select notes from 1-1000181-1 where current_slogan = south_australia </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: min\n","Target: notes\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: registration_no.\n","Target: notes\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","Predicted: <\n","Target: from\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 1-17369472-2\n","Target: 1-1000181-1\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 3/56355 [00:01<6:35:49,  2.37it/s]\n","  0%|          | 2/7939 [00:00<06:40, 19.83it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> what is the winning song for the artist with a debut album \" the winner \" ? </s>\n","SQL: <s> select winning_song from 1-1646960-3 where debut_album = the_winner </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: grand_final_dual_television_commentator\n","Target: winning_song\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 2-10826385-14\n","Target: 1-1646960-3\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0    total_cost =  115.3135757446289    validLoss = 124.0158576965332\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/56355 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> tell me what the notes are for south australia </s>\n","SQL: <s> select notes from 1-1000181-1 where current_slogan = south_australia </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: min\n","Target: notes\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: registration_no.\n","Target: notes\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 2-1122914-2\n","Target: 1-1000181-1\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 3/56355 [00:01<6:51:47,  2.28it/s]\n","  0%|          | 2/7939 [00:00<08:42, 15.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> in what round was the draft pick from florida with an overall less than 166 ? </s>\n","SQL: <s> select avg round from 2-15198842-33 where college = florida and overall < florida </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: count\n","Target: avg\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 3\n","Predicted: react\n","Target: round\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 4\n","Predicted: <\n","Target: from\n","\n","\n","Current Decoder: TableDecoder\n","i = 5\n","Predicted: 2-1204658-9\n","Target: 2-15198842-33\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 6\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1    total_cost =  112.42851066589355    validLoss = 126.83207702636719\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/56355 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> tell me what the notes are for south australia </s>\n","SQL: <s> select notes from 1-1000181-1 where current_slogan = south_australia </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: min\n","Target: notes\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: net_run_rate\n","Target: notes\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","Predicted: <\n","Target: from\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 1-17993994-5\n","Target: 1-1000181-1\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 3/56355 [00:01<6:50:12,  2.29it/s]\n","  0%|          | 2/7939 [00:00<07:47, 16.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> what years did bobby moore play ? </s>\n","SQL: <s> select nasl_years from 1-237757-9 where player = <none> </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: sum\n","Target: nasl_years\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: sri_lankan_moors\n","Target: nasl_years\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 1-17311797-11\n","Target: 1-237757-9\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2    total_cost =  152.34536933898926    validLoss = 123.40867805480957\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/56355 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> tell me what the notes are for south australia </s>\n","SQL: <s> select notes from 1-1000181-1 where current_slogan = south_australia </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: sum\n","Target: notes\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: current_3_november_2013\n","Target: notes\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 2-1616581-1\n","Target: 1-1000181-1\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n","Predicted: where\n","Target: where\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 6\n","Predicted: governor\n","Target: current_slogan\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 7\n","Predicted: >\n","Target: =\n","\n","\n","Current Decoder: ConstantDecoder\n","i = 8\n","Predicted: 2-17651219-1\n","Target: south_australia\n","\n","\n","Current Decoder: AndOrDecoder\n","i = 9\n","Predicted: and\n","Target: </s>\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 3/56355 [00:01<7:16:26,  2.15it/s]\n","  0%|          | 2/7939 [00:00<12:18, 10.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> what is the average when 2nd highest was <none> ? </s>\n","SQL: <s> select max average from 1-237757-10 where 2nd_highest = <none> </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: sum\n","Target: max\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 3\n","Predicted: shigella\n","Target: average\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 4\n","Predicted: <\n","Target: from\n","\n","\n","Current Decoder: TableDecoder\n","i = 5\n","Predicted: 2-11503671-1\n","Target: 1-237757-10\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 6\n","Predicted: where\n","Target: where\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 7\n","Predicted: foreign_nationality\n","Target: 2nd_highest\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 8\n","Predicted: <\n","Target: =\n","\n","\n","Current Decoder: ConstantDecoder\n","i = 9\n","Predicted: the_netherlands\n","Target: <none>\n","\n","\n","Current Decoder: AndOrDecoder\n","i = 10\n","Predicted: and\n","Target: </s>\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3    total_cost =  171.38968658447266    validLoss = 138.30385208129883\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/56355 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> tell me what the notes are for south australia </s>\n","SQL: <s> select notes from 1-1000181-1 where current_slogan = south_australia </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: sum\n","Target: notes\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: registration_no.\n","Target: notes\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","Predicted: <\n","Target: from\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 1-17369472-2\n","Target: 1-1000181-1\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 3/56355 [00:01<8:34:13,  1.83it/s]\n","  0%|          | 2/7939 [00:00<08:00, 16.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Text: <s> in womens doubles and mens <none> what years did <none> <none> or <none> <none> <none> <none> win ? </s>\n","SQL: <s> select womens_doubles from 1-12194021-1 where mens_singles = <none> and mixed_doubles = <none> </s>\n","\n","\n","Current Decoder: RootDecoder\n","i = 0\n","\n","\n","Current Decoder: AggregatorDecoder\n","i = 2\n","Predicted: avg\n","Target: womens_doubles\n","\n","\n","Current Decoder: ColumnDecoder\n","i = 2\n","Predicted: trekking_route\n","Target: womens_doubles\n","\n","\n","Current Decoder: OperatorDecoder\n","i = 3\n","Predicted: =\n","Target: from\n","\n","\n","Current Decoder: TableDecoder\n","i = 4\n","Predicted: 1-17030926-3\n","Target: 1-12194021-1\n","\n","\n","Current Decoder: KeywordDecoder\n","i = 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4    total_cost =  149.5994110107422    validLoss = 154.22818565368652\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkr5IC13pZTyQVruSinlg/4/Mfzc7tx3yU0AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6wL8QYpgdTCd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}